# 修复分布式验证评估 Bug 和添加调试代码

## 修改日期
2025-12-07

## 问题描述

### 问题 1: 验证集指标完全不变
**现象**：MPJPE: 102.152 mm, PA-MPJPE: 48.320 mm 从 epoch 0 到 epoch 7 完全不变

**根本原因**：
在分布式训练（4个GPU）中：
1. `val_loader` 使用了 `DistributedSampler`，每个进程只看到 1/4 的验证数据
2. `Evaluator` 只在 rank 0 上创建和使用
3. rank 0 每个 epoch 都评估**完全相同的样本子集**（DistributedSampler 的 shuffle=False）
4. 其他 3 个进程的预测结果被丢弃

**验证**：
- 8333 个验证样本 / 4 个GPU = 2083 个样本/进程
- rank 0 只评估 2083 个样本，且每次都是相同的样本
- 所以指标完全不变

### 问题 2: 3D joint loss 过高且不下降
**现象**：3D joint loss 一直在 75000-80000 之间波动，完全不下降

**可能原因**：
- 数据预处理问题（重复中心化？单位转换错误？）
- Loss 计算问题（GT 已经是相对坐标？）
- 模型输出尺度问题

## 解决方案

### 方案 1: 修复分布式验证评估（Critical Fix）

#### 修改位置：`UTNet/train.py:431-550`

#### 核心改动：

**之前的实现**：
```python
# 在循环中直接调用 evaluator
for batch in dataloader:
    # ... forward pass ...
    evaluator(pred_keypoints_3d, gt_keypoints_3d)  # ❌ 只评估 rank 0 的数据

# 直接获取指标
metrics_dict = evaluator.get_metrics_dict()  # ❌ 只包含 1/4 的数据
```

**新实现**：
```python
# 1. 收集所有批次的预测和GT
all_pred_keypoints = []
all_gt_keypoints = []

for batch in dataloader:
    # ... forward pass ...
    all_pred_keypoints.append(pred_keypoints_3d.cpu())
    all_gt_keypoints.append(gt_keypoints_3d.cpu())

# 2. 在分布式训练中，收集所有GPU的数据到rank 0
if distributed:
    local_pred = torch.cat(all_pred_keypoints, dim=0)
    local_gt = torch.cat(all_gt_keypoints, dim=0)
    
    # 先收集各个进程的数据大小（因为可能不同）
    local_size = torch.tensor([local_pred.shape[0]], device=device)
    size_list = [torch.zeros(1, device=device) for _ in range(world_size)]
    dist.all_gather(size_list, local_size)
    
    if rank == 0:
        # 根据各进程的实际大小，接收数据
        for i, size in enumerate(size_list):
            if i == rank:
                # 使用本地数据
                all_preds_list.append(local_pred.cpu())
            else:
                # 从其他进程接收
                recv_pred = torch.zeros(size.item(), J, 3, device=device)
                dist.recv(recv_pred, src=i)
                all_preds_list.append(recv_pred.cpu())
        
        all_pred = torch.cat(all_preds_list, dim=0)  # ✅ 包含所有GPU的数据
        all_gt = torch.cat(all_gts_list, dim=0)
        
        # 分批评估
        evaluator.counter = 0
        for i in range(0, all_pred.shape[0], eval_batch_size):
            evaluator(all_pred[i:end_idx], all_gt[i:end_idx])
    else:
        # 非rank 0进程：发送数据到rank 0
        dist.send(local_pred.to(device), dst=0)
        dist.send(local_gt.to(device), dst=0)
```

#### 关键优化：

1. **动态大小处理**：先使用 `dist.all_gather` 收集各进程的数据大小
2. **收集所有GPU数据**：使用 `dist.send/recv` 将所有进程的预测收集到 rank 0
   - 支持各进程数据大小不同的情况（DistributedSampler 可能导致）
3. **评估完整数据集**：rank 0 评估所有 8333 个样本，而不只是 2083 个
4. **分批评估**：使用 256 的批次大小避免内存问题
5. **内部重置 counter**：test 函数内部处理 evaluator.counter 的重置

#### 为什么不用 `dist.gather`？

`dist.gather` 要求所有进程的 tensor 大小完全相同，但在分布式训练中：
- 8332 个验证样本 / 4 个GPU = 2083 个/GPU（正好整除，无问题）
- 但其他数据集可能不能整除，导致最后一个GPU样本数不同
- 使用 `dist.send/recv` + 先收集大小的方法更通用和健壮

### 方案 2: 添加调试代码

#### 修改位置 1：`UTNet/train.py:348-362`

在 `train_epoch` 函数中添加数据统计输出（前 3 个 batch）：

```python
# Debug: Print data statistics for first few batches of first epoch
if rank == 0 and epoch == 0 and batch_idx < 3:
    print(f'\n[Debug Batch {batch_idx}]')
    print(f'  RGB range: [{rgb.min():.3f}, {rgb.max():.3f}]')
    if depth is not None:
        print(f'  Depth range: [{depth.min():.3f}, {depth.max():.3f}]')
    print(f'  GT 3D joints mean: {keypoints_3d.mean():.3f}, std: {keypoints_3d.std():.3f}')
    print(f'  Pred 3D joints mean: {predictions["keypoints_3d"].mean():.3f}, std: {predictions["keypoints_3d"].std():.3f}')
    print(f'  GT root joint: {keypoints_3d[0, 0, :]}')
    print(f'  Pred root joint: {predictions["keypoints_3d"][0, 0, :]}')
    
    # Check if GT is already centered
    gt_centered_by_root = keypoints_3d - keypoints_3d[:, [0], :]
    print(f'  GT centered by root mean: {gt_centered_by_root.mean():.3f}, std: {gt_centered_by_root.std():.3f}')
```

#### 修改位置 2：`UTNet/src/losses/loss.py:64-106`

在 `Keypoint3DLoss.forward` 中添加调试输出（通过环境变量控制）：

```python
# 使用环境变量 UTNET_DEBUG_LOSS=1 启用
if os.environ.get('UTNET_DEBUG_LOSS', '0') == '1':
    print(f'[Debug 3D Loss]')
    print(f'  Before centering - Pred mean: {pred_keypoints_3d.mean():.3f}')
    print(f'  Before centering - GT mean: {gt_keypoints_3d[:, :, :-1].mean():.3f}')
    # ... 中心化代码 ...
    print(f'  After centering - Pred mean: {pred_keypoints_3d.mean():.3f}')
    print(f'  After centering - GT mean: {gt_keypoints_3d.mean():.3f}')
    print(f'  Loss value: {loss.sum().item():.3f}')
```

**启用方式**：
```bash
export UTNET_DEBUG_LOSS=1
python train.py --config config/config.yaml
```

### 方案 3: 改进日志输出

修改 `train.py:492` 的进度条描述从 `'Test {epoch}'` 改为 `'Val {epoch}'`，与函数重命名保持一致。

修改 `train.py:838` 移除外部的 `val_evaluator.counter = 0` 重置，由 `test()` 函数内部处理。

## 修改文件列表

1. **UTNet/train.py**
   - 修改 `create_dataloader` 函数，支持 HO3D train/val 划分
   - 完全重写 `test` 函数，实现分布式数据收集和评估
   - 在 `train_epoch` 中添加调试代码（前 3 个 batch）
   - 更新所有 `test_*` 变量名为 `val_*`
   - 移除外部的 evaluator counter 重置

2. **UTNet/config/config.yaml**
   - 添加 `val_split_ratio: 0.1` 参数

3. **UTNet/src/losses/loss.py**
   - 在 `Keypoint3DLoss.forward` 中添加可选调试输出

## 预期效果

### 修复后的验证流程

1. **数据划分**（仅 HO3D）：
   - Train: 74,993 个样本（90%）
   - Val: 8,332 个样本（10%）
   - 使用固定随机种子 (42) 确保可复现

2. **分布式验证**（4个GPU）：
   - 每个GPU处理 ~2,083 个验证样本
   - 所有GPU的预测被收集到 rank 0
   - rank 0 评估完整的 8,332 个样本
   - **指标会随着训练变化，不再固定**

3. **调试输出示例**：
```
[Debug Batch 0]
  RGB range: [-2.118, 2.640]
  Depth range: [0.000, 1.000]
  GT 3D joints mean: 125.345, std: 87.234
  Pred 3D joints mean: 98.765, std: 102.456
  GT root joint: tensor([123.45, 234.56, 345.67])
  Pred root joint: tensor([98.76, 187.65, 298.43])
  GT centered by root mean: 0.000, std: 87.234

[Debug 3D Loss] (if UTNET_DEBUG_LOSS=1)
  Before centering - Pred mean: 98.765, std: 102.456
  Before centering - GT mean: 125.345, std: 87.234
  After centering - Pred mean: 0.000, std: 102.456
  After centering - GT mean: 0.000, std: 87.234
  Loss value: 78234.567
```

## 诊断步骤

### 步骤 1: 运行一个 epoch 查看调试输出

```bash
cd /data0/users/Robert/linweiquan/UTNet
torchrun --nproc_per_node=4 train.py --config config/config.yaml
```

### 步骤 2: 检查调试输出

查看第一个 epoch 的前 3 个 batch 的调试信息，检查：
- ✅ GT 3D joints 的 mean 是否合理（应该在 0-500 mm 范围）
- ✅ GT centered by root 的 mean 是否接近 0（应该非常接近 0）
- ✅ Pred 和 GT 的 std 是否在同一数量级
- ❌ 如果 GT centered mean 不为 0，说明**数据已经被中心化过，loss 函数不应再次中心化**

### 步骤 3: 启用 Loss 调试（如果需要）

```bash
export UTNET_DEBUG_LOSS=1
torchrun --nproc_per_node=4 train.py --config config/config.yaml
```

查看 loss 函数内部的中心化前后数据变化。

### 步骤 4: 根据诊断结果修复

**情况 A：GT 已经是相对坐标**
- 修改数据加载器，返回绝对坐标
- 或修改 loss 函数，移除中心化步骤

**情况 B：单位转换错误**
- 检查 `* 1000` 操作是否重复
- 检查 MANO 输出单位

**情况 C：坐标系映射错误**
- 检查 HO3D2MANO 映射是否正确
- 检查数据加载时的坐标变换

## 验证标准

修复成功的标志：
1. ✅ 验证集指标会随训练变化（不再固定）
2. ✅ 3D joint loss 应该逐渐下降
3. ✅ MPJPE 和 PA-MPJPE 应该逐渐降低
4. ✅ Total loss 应该逐渐下降

预期的合理数值：
- 初始 3D loss: 1000-5000（相对坐标，mm单位）
- 收敛后 3D loss: < 500
- 初始 MPJPE: 80-120 mm
- 收敛后 MPJPE: 10-30 mm

